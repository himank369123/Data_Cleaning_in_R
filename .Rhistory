?replace
##lab4
##1)
interest<-function(p,r,n,t){
p*((1+(r/n))^(n*t))-p
}
interest(2000,0.03,1,5)
##2)
area<-pi*7*7
area
##3)
identical(48:14^2,48:(14^2))
##4)
a<-rep(0:4,each=5)
a
b<-rep(1:5,5)
b
grep(0,x=a)
##5)
vec<-rep(c(rep(0,3),rep(1,4)),5)
vec1<-as.factor(vec)
vec1
levels(vec1)<-c("a","b")
vec1
levels(vec1)<-c("Male","Female")
vec1
##6)
?more.colors
##6)
more.colors<-c("r","y",'b','y','b','g','b','g','m','g','m','c')
grep(more,colors,'b')
more.colors
rm(list=ls())
seq(more.colors)
seq(1,10,more.colors)
seq(1,10,more.colors=c("R"))
seq(1,10)
?seq
seq(1,10,col=3)
rep(1,10,col=3)
rep(1,10,col=4)
?rep
palette()
palette(2)
palette[2]
more.colors
more.colors
palette
?palette
palette("a")
palette("red")
palette
palette("1")
palette(1)
palette(rainbow(6))
for(i in 1:5)
j=i+4
seq(i,j)
}
for(i in 1:5)
j=i+4
a<-c(a,seq(i,j))
}
for(i in 1:5)
j=i+4
a<-paste(a,seq(i,j))
}
1:5+rep(0:4,by=5)
a<-numeric()
for(i in 1:5)
j=i+4
a<-paste(a,seq(i,j))
}
a<-numeric()
for(i in 1:5){
j=i+4
a<-paste(a,seq(i,j))
}
a
as.numeric(a)
a<-numeric()
for(i in 1:5){
j=i+4
as.numeric(a)
a<-paste(a,seq(i,j))
}
a<-numeric()
for(i in 1:5){
j=i+4
a<-paste(a,seq(i,j))
}
a
a<-numeric()
for(i in 1:5){
j=i+4
a<-paste(a,seq(i,j))
}
a
sapply(a,as.numeric)
class(a)
a<-numeric()
for(i in 1:5){
j=i+4
a<-paste(a,seq(i,j))
}
class(a)
1:5+rep(0:4,each=5)
?cor
fileurl<-"https://www.w3schools.com/xml/simple.xml"
## default format:
## xpathSApply(rootnode)
library(XML)
library(RCurl)
xdata<-getURL(fileurl)
doc<-xmlTreeParse(xdata,useInternal=TRUE)
rootnode<-xmlRoot(doc)
xmlName(rootnode)
names(rootnode)
rootnode[[1]][[1]]
xmlSApply(rootnode,xmlValue)
xpathSApply(rootnode,"//name",xmlValue)
xpathSApply(rootnode,"//price",xmlValue)
xpathSApply(rootnode,"//name",xmlValue)
xpathSApply(doc,"//name",xmlValue)
xpathSApply(doc,"//price",xmlValue)
names(rootnode)
names(doc)
names(rootnode)
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(XML)
html<-xmlTreeParse(url)
xpathSApply(html,"//gsc_a_y",xmlValue())
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(XML)
html<-htmlTreeParse(url)
xpathSApply(html,"//gsc_a_y",xmlValue())
html<-htmlTreeParse(url)
xpathSApply(html,"//gsc_a_y",xmlValue())
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(XML)
html<-htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html,"//gsc_a_y",xmlValue())
xpathSApply(html,"//title",xmlValue())
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(XML)
html<-htmlTreeParse(url,useInternalNodes = T)
xpathSApply(html,"//title",xmlValue())
html<-htmlTreeParse(url,useInternalNodes = T)
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html<-htmlTreeParse(url,useInternalNodes = T)
library(RCurl)
pageurl<-getURL(url)
html<-htmlTreeParse(pageurl,useInternalNodes = T)
xpathSApply(html,"//gsc_a_y",xmlValue())
xpathSApply(html,"//title",xmlValue())
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(XML)
library(RCurl)
pageurl<-getURL(url)
html<-htmlTreeParse(pageurl,useInternalNodes = T)
xpathSApply(html,"//title",xmlValue())
library(rvest)
html<-read_html(url)
html%>% html_nodes('.title')%>%html_text()
html%>% html_nodes('.title')%>%html_text()
html%>% html_nodes('.title')%>%html_text()
html%>% html_nodes('.title')%>%html_text()
html%>% html_nodes('.title')%>%html_text()
html%>% html_nodes('.title')%>%html_text()
library(stringr)
html%>% html_nodes('.title')%>%html_text()%>%str_trim()%>%unlist()
html%>% html_nodes('.title')%>%html_text()%>%str_trim()%>%unlist()
html%>% html_nodes('.title')%>%html_text()%>%str_trim()%>%unlist()
html%>% html_nodes('.title')%>%html_text()%>%str_trim()%>%unlist()
html%>% html_nodes('.title')%>%html_text%>%str_trim%>%unlist()
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(rvest)
library(stringr)
html<-read_html(url)
html%>% html_nodes('.title')%>%html_text%>%str_trim%>%unlist()
html%>% html_nodes('.gsc_lcl')%>%html_text%>%str_trim%>%unlist()
html%>% html_nodes('.gsc_a_at')%>%html_text%>%str_trim%>%unlist()
html%>% html_nodes('.gsc_a_ac gs_ibl')%>%html_text%>%str_trim%>%unlist()
html%>% html_nodes('.gsc_a_ac gs_ibl')%>%html_text%>%str_trim%>%unlist()
html%>% html_nodes('.gsc_a_ac gs_ibl')%>%html_text%>%str_trim%>%unlist()
html%>% html_nodes('.gsc_a_ac gs_ibl')%>%html_text%>%unlist()
html%>% html_nodes('.gsc_a_ac gs_ibl')%>%html_text%>%unlist()
html%>% html_nodes('.gsc_a_ac gs_ibl')%>%html_text
html%>% html_nodes('.gsc_a_tr')%>%html_text%>%str_trim%>%unlist()
html%>% html_nodes('.gsc_a_c')%>%html_text%>%str_trim%>%unlist()
library(XML)
library(RCurl)
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
getURL(url)
html<-getURL(url)
htmlTreeParse(html,useInternalNodes = T)
ht<-htmlTreeParse(html,useInternalNodes = T)
xpathSApply(ht,".title",xmlValue)
xpathSApply(ht,"//title",xmlValue)
xpathSApply(ht,"//td[@id='col-citedby']",xmlValue)
xpathSApply(ht,"//td[@id='col-citedby']",xmlValue)
xpathSApply(ht,"//td[@id='col-citedby']",xmlValue)%>% unlist()
xpathSApply(ht,"//gsc_a_c']",xmlValue)
xpathSApply(ht,"//td[@class='gsc_a_c']",xmlValue)
xpathSApply(ht,"//td[@class='gsc_a_c']",xmlValue)
library(XML)
library(RCurl)
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html<-getURL(url)
ht<-htmlTreeParse(html,useInternalNodes = T)
xpathSApply(ht,"//td[@class='gsc_a_c']",xmlValue)
xpathSApply(ht,"//a[@class='gsc_a_ac gs_ibl']",xmlValue)
xpathSApply(ht,"//td[@id='gsc_a_c]",xmlValue)
xpathSApply(ht,"//td[@id='gsc_a_c']",xmlValue)
xpathSApply(ht,"//*[contains(concat( " ", @class, " " ), concat( " ", "gsc_a_c", " " ))]",xmlValue)
xpathSApply(ht,"//*[contains(concat( " ", @class, " " ), concat( " ", 'gsc_a_c', " " ))]",xmlValue)
xpathSApply(ht,'//*[contains(concat( " ", @class, " " ), concat( " ", "gsc_a_c", " " ))]',xmlValue)
xpathSApply(ht,'//*[contains(concat( " ", @class, " " ), concat( " ", "gsc_a_c", " " ))]',xmlValue)
xpathSApply(ht,'//*[contains(concat( " ", @class, " " ), concat( " ", "gsc_a_ac", " " ))] | //*[contains(concat( " ", @class, " " ), concat( " ", "gsc_a_tr", " " )) and (((count(preceding-sibling::*) + 1) = 1) and parent::*)]//*[contains(concat( " ", @class, " " ), concat( " ", "gsc_a_c", " " ))]',xmlValue)
xpathSApply(ht,'//*[@class="gsc_a_c"]',xmlValue)
xpathSApply(ht,'//*[@class="gsc_a_c"]',xmlValue)
xpathSApply(ht,'//*[@class="gsc_a_ac gs_ibl"]',xmlValue)
xpathSApply(ht,'//a[@class="gsc_a_ac gs_ibl"]',xmlValue)
xpathSApply(ht,'//a[@class="gsc_a_ac"]',xmlValue)
xpathSApply(ht,"//a[@class='gsc_a_ac']",xmlValue)
ht<-htmlParse(html,useInternalNodes = T)
xpathSApply(ht,"//a[@class='gsc_a_ac']",xmlValue)
xpathSApply(ht,"//a[@class='gsc_a_ac']",xmlValue)
library(XML)
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ"
parsedhtml<-htmlParse(url)
parsedhtml["//a[@class='gsc_a_ac']", fun = xmlValue]
parsedhtml<-htmlParse(url)
library(XML)
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
parsedhtml<-htmlParse(url)
parsedhtml["//a[@class='gsc_a_ac']", fun = xmlValue]
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
parsedhtml<-htmlParse(url)
url<-"https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
parsedhtml<-htmlParse(url)
html<-getURL(url)
parsedhtml<-htmlParse(html)
parsedhtml<-htmlParse(html)
parsedhtml["//a[@class='gsc_a_ac']", fun = xmlValue]
url<-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(rvest)
library(stringr)
html<-read_html(url)
html%>% html_nodes('.gsc_a_c')%>%html_text%>%str_trim%>%unlist()
library(httr)
html2<-GET(url)
library(httr)
html2<-GET(url)
content2<-content(html2,as="text")
parsedHtml=htmlParse(content2,asText = T)
xpathSApply(parsedHtml,"//title",xmlValue)
library(httr)
html2<-getURL(url)
content2<-content(html2,as="text")
parsedHtml=htmlParse(content2,asText = T)
xpathSApply(parsedHtml,"//title",xmlValue)
html2<-getURL(url)
content2<-content(html2,as="text")
html2<-GET(url)
xpathSApply(parsedHtml,"//a[@class='gsc_a_ac gs_ibl']",xmlValue)
xpathSApply(parsedHtml,"//td[@class='gsc_a_c",xmlValue)
xpathSApply(parsedHtml,"//td[@class='gsc_a_c']",xmlValue)
xpathSApply(parsedHtml,'//*[contains(concat( " ", @class, " " ), concat( " ", "gs_ibl", " " ))]',xmlValue)
xpathSApply(parsedHtml,'//*[contains(concat( " ", @class, " " ), concat( " ", "gsc_a_ac", " " ))]',xmlValue)
library(httr)
library(httr)
library(XML)
url<-"https://www.quora.com/"
page<-GET(url)
xpathSApply(page,'//*[(@id = "js_h2")]//*[contains(concat( " ", @class, " " ), concat( " ", "profileLink", " " ))] | //*[(@id = "js_ga")]//a | //*[(@id = "js_9p")]//a | //*[contains(concat( " ", @class, " " ), concat( " ", "_6qw4", " " ))]',xmlValue
library(httr)
library(XML)
url<-"https://www.facebook.com/himank.jain.3762"
page<-GET(url)
xpathSApply(page,'//*[(@id = "js_h2")]//*[contains(concat( " ", @class, " " ), concat( " ", "profileLink", " " ))] | //*[(@id = "js_ga")]//a | //*[(@id = "js_9p")]//a | //*[contains(concat( " ", @class, " " ), concat( " ", "_6qw4", " " ))]',xmlValue)
library(httr)
library(XML)
url<-"https://www.facebook.com/himank.jain.3762"
page<-GET(url)
xpathSApply(page,'//*[(@id = "js_h2")]//*[contains(concat( " ", @class, " " ), concat( " ", "profileLink", " " ))] | //*[(@id = "js_ga")]//a | //*[(@id = "js_9p")]//a | //*[contains(concat( " ", @class, " " ), concat( " ", "_6qw4", " " ))]',xmlValue)
url<-"https://www.facebook.com/himank.jain.3762"
page<-GET(url)
page
library(httr)
library(XML)
url<-"https://www.analyticsindiamag.com/9-best-data-science-blogs-to-follow-in-2019/"
page<-GET(url)
xpathSApply(page,'//b',xmlValue)
page<-GET(url)
page
xpathSApply(page,'//b',xmlValue)
library(httr)
library(XML)
url<-"https://www.analyticsindiamag.com/9-best-data-science-blogs-to-follow-in-2019/"
page<-GET(url)
html<-htmlParse(page)
xpathSApply(html,'//b',xmlValue)
length("84dc9f923b8b3119881ae4456d6d46faaeafe6a1")
nchar("84dc9f923b8b3119881ae4456d6d46faaeafe6a1")
library(httr)
oauth_endpoints("github")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "2434e17aded5a0dcdcb3",
secret = "21fd90a0d26afcbfe5407c58cf6bc3eec0f4e715"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
View(gtoken)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "2434e17aded5a0dcdcb3",
secret = "21fd90a0d26afcbfe5407c58cf6bc3eec0f4e715"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
content(req)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "2434e17aded5a0dcdcb3",
secret = "21fd90a0d26afcbfe5407c58cf6bc3eec0f4e715"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
content(req)
con<-content(req)
unlist(con)
str(con)
con
oauth_app
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("Coursera_jtleek",
key = "2434e17aded5a0dcdcb3",
secret = "21fd90a0d26afcbfe5407c58cf6bc3eec0f4e715"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
con<-content(req)
con
library(jsonlite)
library(httr)
library(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("Coursera_jtleek",
key = "2434e17aded5a0dcdcb3",
secret = "21fd90a0d26afcbfe5407c58cf6bc3eec0f4e715"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
con<-content(req)
df<-fromJSON(toJSON(con))
df[df$full_name=="jtleek/datasharing","created"]
library(httr)
library(jsonlite)
oauth_endpoints("github")
myapp <- oauth_app("Coursera_jtleek",
key = "2434e17aded5a0dcdcb3",
secret = "21fd90a0d26afcbfe5407c58cf6bc3eec0f4e715"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
con<-content(req)
df<-fromJSON(toJSON(con))
df[df$full_name=="jtleek/datasharing","created_at"]
df
getwd()
setwd("DataCleaning")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",destfile ="ACS") )
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",destfile ="ACS" )
read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
acs<-read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",header = T)
install.packages("sqldf")
library(sqldf)
sqldf("select * from acs where pwgtp1<50")
sqldf("select pwgtp1 from acs where ages<50")
sqldf("select pwgtp1 from acs where AGES<50")
sqldf("select pwgtp1 from acs where AGEP<50")
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
library(XML)
library(httr)
library(httr)
url<-"http://biostat.jhsph.edu/~jleek/contact.html"
page<-GET(url)
html<-htmlParse(page)
content(html)
html
content(html)
html[10]
?htmlParse
html<-htmlParse(page,asText=T)
content(html)
html
class(html)
html[10]
readLines(html)
?readLines
readLines(page)
con<-url(url)
readLines(con)
page<-readLines(con)
page[10]
nchar(page[10])
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",destfile = "wks.for")
read.table("wks.for")
scan("wks.for")
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",destfile = "wks.for")
readLines(url,n=10)
lines<-readLines(url,n=10)
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",destfile = "wks.for")
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",destfile = "wks.for")
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for",destfile = "wks.for")
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"()
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
url<-("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
lines<-readLines(url,n=10)
lines
lines<-readLines(url,n=15)
lines<-readLines(url,n=10)
lines<-readLines(url,n=15)
lines
nameofcol<-("filler","week","filler","sstnino12","filler","sstanino12","filler","sstnino3","filler","sstanino3","filler","sstnino34","filler","sstanino34","filler","sstnino4","filler","sstanino4")
nameofcol<-c("filler","week","filler","sstnino12","filler","sstanino12","filler","sstnino3","filler","sstanino3","filler","sstnino34","filler","sstanino34","filler","sstnino4","filler","sstanino4")
df<-read.fwf(url,col.names = nameofcol,header=F,skip=4,)
widths<-c(1,9,5,4,1,3,5,4,1,3,5,4,1,3,5,4,1,3)
df<-read.fwf(url,col.names = nameofcol,header=F,skip=4,widths = widths)
df
df[,-c(1,3,5,7,9)]
df[,-c(1,3,5,7,9,11,13)]
df[,-c(1,3,5,7,9,11,13,15,17)]
new_df<-df[,-c(1,3,5,7,9,11,13,15,17)]
?grep
grep("^[^filler]",names(df))
grep(-"filler",names(df))
grep("filler",names(df))
grep("[filler]",names(df))
grep("[filler]^",names(df))
grep("^[^filler]^",names(df))
grep("^[^filler^]",names(df))
grep("^[^filler]",names(df))
grep("^[^filler]",names(df))
grep("^[filler]",names(df))
grep("^[^filler]",names(df))
grep("[^filler]",names(df))
grep("^[^filler]",names(df))
sum(df[,4])
sum(df[,5]]
sum(df[,5])
sum(df[,3])
sum(df[,3])
sum(df[,4])
sum(df[,4],na.rm=T)
df
sum(new_df[,4])
## brackets are imp. ^([Gg]ood|[Bb]ad) searches for strings stargin with Good/good/Bad/bad. not just anywhere.
## ? metacharachter is for options. for eg: george([Ww]\.)? bush searches for george bush or something in b/w george and bush.
##\ is used for escaping character i.e. making a metacharcter into literal. like in above example. otherwise it might treat . as metacharacter.
## + is used to denote atleast one charcter repetetion, (.*) means any no. of reps including none.
## {1,5} means atleast match and max 5 matches. eg.
## bush( +[^ ]+ +){1,5} debate. looks for lines starting ending with bush and that has 1 to 5 words in b/w them.
## escape numbers like \1 \2,etc can be used to remember exp in parenthesis (). eg:
## +([a-zA-Z]+) +\1 +  this searches for lines with space word exact word space. eg: night night, blah blah blah, etc.
## (.*) is greedy. it looks for longeest match. the greediness can be turned off using (.*?)
## literals and metachars are best used with grep,gsub,sub to manipulate text.
grep("a+", c("abc", "def", "cba a", "aa"), perl=TRUE, value=TRUE)
## brackets are imp. ^([Gg]ood|[Bb]ad) searches for strings stargin with Good/good/Bad/bad. not just anywhere.
## ? metacharachter is for options. for eg: george([Ww]\.)? bush searches for george bush or something in b/w george and bush.
##\ is used for escaping character i.e. making a metacharcter into literal. like in above example. otherwise it might treat . as metacharacter.
## + is used to denote atleast one charcter repetetion, (.*) means any no. of reps including none.
## {1,5} means atleast match and max 5 matches. eg.
## bush( +[^ ]+ +){1,5} debate. looks for lines starting ending with bush and that has 1 to 5 words in b/w them.
## escape numbers like \1 \2,etc can be used to remember exp in parenthesis (). eg:
## +([a-zA-Z]+) +\1 +  this searches for lines with space word exact word space. eg: night night, blah blah blah, etc.
## (.*) is greedy. it looks for longeest match. the greediness can be turned off using (.*?)
## literals and metachars are best used with grep,gsub,sub to manipulate text.
grep("a.*", c("abc", "def", "cba a", "aa"), perl=TRUE, value=TRUE)
## brackets are imp. ^([Gg]ood|[Bb]ad) searches for strings stargin with Good/good/Bad/bad. not just anywhere.
## ? metacharachter is for options. for eg: george([Ww]\.)? bush searches for george bush or something in b/w george and bush.
##\ is used for escaping character i.e. making a metacharcter into literal. like in above example. otherwise it might treat . as metacharacter.
## + is used to denote atleast one charcter repetetion, (.*) means any no. of reps including none.
## {1,5} means atleast match and max 5 matches. eg.
## bush( +[^ ]+ +){1,5} debate. looks for lines starting ending with bush and that has 1 to 5 words in b/w them.
## escape numbers like \1 \2,etc can be used to remember exp in parenthesis (). eg:
## +([a-zA-Z]+) +\1 +  this searches for lines with space word exact word space. eg: night night, blah blah blah, etc.
## (.*) is greedy. it looks for longeest match. the greediness can be turned off using (.*?)
## literals and metachars are best used with grep,gsub,sub to manipulate text.
grep("a+", c("abc", "def", "cba a", "aa"), perl=TRUE, value=TRUE)
